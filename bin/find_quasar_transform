#!/usr/bin/env python

import sys
import argparse
import subprocess

import numpy
import h5py
import hifive
from mpi4py import MPI

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
num_procs = comm.Get_size()

def main():
    if rank == 0:
        print >> sys.stderr, ("\r%s\rLoading counts") % (' ' * 120),
        parser = generate_parser()
        args = parser.parse_args()
        args.RNG = numpy.random.RandomState(seed=args.seed)
        args.resolution = args.resolution.split(',')
        for i in range(len(args.resolution)):
            args.resolution[i] = int(args.resolution[i])

        # Determine valid chromosomes
        hic = hifive.HiC(args.input)
        chromosomes = hic.fends['chromosomes'][...]
        chroms = []
        if args.chroms == '':
            for i in range(1, 23):
                if numpy.where(chromosomes == str(i))[0].shape[0] > 0:
                    chroms.append(str(i))
            if numpy.where(chromosomes == 'X')[0].shape[0] > 0:
                chroms.append('X')
        else:
            for chrom in args.chroms:
                if numpy.where(chromosomes == chrom.strip('chr'))[0].shape[0] > 0:
                    chroms.append(chrom.strip('chr'))
        args.chroms = chroms

        # Load raw counts
        if 'binned' in hic.__dict__ and hic.binned is not None:
            temp_mids = hic.fends['bins']['mid'][...]
            chr_indices = hic.fends['bin_indices'][...]
        else:
            temp_mids = hic.fends['fends']['mid'][...]
            chr_indices = hic.fends['chr_indices'][...]
        bounds = numpy.zeros((len(args.chroms), 2), numpy.int64)
        for i, chrom in enumerate(args.chroms):
            chrint = hic.chr2int[chrom]
            bounds[i, 0] = hic.data['cis_indices'][chr_indices[chrint]]
            bounds[i, 1] = hic.data['cis_indices'][chr_indices[chrint + 1]]
        raw = numpy.zeros((numpy.sum(bounds[:, 1] - bounds[:, 0]), 3), dtype=numpy.int64)
        indices = numpy.zeros(len(args.chroms) + 1, dtype=numpy.int64)
        mids = {}
        starts = numpy.zeros(len(args.chroms), dtype=numpy.int32)
        for i, chrom in enumerate(args.chroms):
            chrint = hic.chr2int[chrom]
            indices[i + 1] = indices[i] + bounds[i, 1] - bounds[i, 0]
            temp = hic.data['cis_data'][bounds[i, 0]:bounds[i, 1], :]
            temp[:, :2] -= chr_indices[chrint]
            raw[indices[i]:indices[i + 1], :] = temp
            mids[chrom] = temp_mids[chr_indices[chrint]:chr_indices[chrint + 1]]
            starts[i] = mids[chrom][0]
        if numpy.sum(raw[:, 2]) < args.coverage:
            args = None
        else:
            outfile = h5py.File(args.output, 'w')
            outfile.create_dataset(name='chromosomes', data=numpy.array(args.chroms))
            outfile.create_dataset(name='resolutions', data=numpy.array(args.resolution))
            outfile.create_dataset(name='starts', data=starts)
            outfile.attrs['coverage'] = args.coverage
            outfile.close()
            if args.coverage > 0:
                raw, indices = downsample(raw, indices, args.coverage, args.RNG)
    else:
        args = None

    # Transfer args and reads
    args = comm.bcast(args, root=0)
    if args is None:
        if rank == 0:
            print >> sys.stderr, ("\r%s\r") % (' ' * 120),
        return None
    chrom_ranges = numpy.round(numpy.linspace(0, len(args.chroms), num_procs + 1)).astype(numpy.int32)
    raw_counts = {}
    if rank == 0:
        print >> sys.stderr, ("\r%s\rTransferring counts") % (' ' * 120),
        for i in range(chrom_ranges[1]):
            chrom = args.chroms[i]
            raw_counts[chrom] = raw[indices[i]:indices[i + 1], :]
        for i in range(1, num_procs):
            for j in range(chrom_ranges[i], chrom_ranges[i + 1]):
                chrom = args.chroms[j]
                comm.send(indices[j + 1] - indices[j], dest=i, tag=1)
                comm.Send(raw[indices[j]:indices[j + 1], :], dest=i, tag=2)
                comm.send(mids[chrom].shape[0], dest=i, tag=3)
                comm.Send(mids[chrom], dest=i, tag=4)
        del raw
    else:
        mids = {}
        for i in range(chrom_ranges[rank], chrom_ranges[rank + 1]):
            chrom = args.chroms[i]
            N = comm.recv(source=0, tag=1)
            raw_counts[chrom] = numpy.zeros((N, 3), dtype=numpy.int64)
            comm.Recv(raw_counts[chrom], source=0, tag=2)
            N = comm.recv(source=0, tag=3)
            mids[chrom] = numpy.zeros(N, dtype=numpy.int32)
            comm.Recv(mids[chrom], source=0, tag=4)

    # Cycle through desired resolutions
    for res in args.resolution:
        dists = {}
        norms = {}
        valids = {}
        corrs = {}

        # For each chromosome, normalize and find distance-corrected matrix
        if rank == 0:
            print >> sys.stderr, ("\r%s\rResolution %i - Normalizing counts") % (' ' * 120, res),
        for chrom in raw_counts:
            norm, dist, valid_rows = normalize(raw_counts[chrom], mids[chrom], res, args.width)
            dists[chrom] = dist
            norms[chrom] = norm
            valids[chrom] = valid_rows
        if rank == 0:
            for i in range(1, num_procs):
                transfer_dict(dists, 0, i)
                transfer_dict(valids, 0, i)
        else:
            transfer_dict(dists, 0, rank)
            transfer_dict(valids, 0, rank)
            dists = None

        # cycle through chromosomes finding correlation matrices
        for i, chrom in enumerate(args.chroms):
            if rank == 0:
                print >> sys.stderr, ("\r%s\rResolution %i - Correlating chrom %s") % (' ' * 120, res, chrom),
            source = numpy.searchsorted(chrom_ranges, i, side='right') - 1
            if rank == source:
                norm = norms[chrom]
                valid_rows = valids[chrom]
                if norm is not None:
                    N = norm.shape[0]
                else:
                    N = None
            else:
                N = None
            N = comm.bcast(N, root=source)
            if N is None:
                if rank == 0:
                    corrs[chrom] = None
                continue
            if rank != source:
                norm = numpy.zeros((N, N), dtype=numpy.float64)
                valid_rows = numpy.zeros(N, dtype=numpy.bool)
            comm.Bcast(norm, root=source)
            comm.Bcast(valid_rows, root=source)
            node_ranges = numpy.round(numpy.linspace(0, N, num_procs + 1)).astype(numpy.int32)
            M = node_ranges[rank + 1] - node_ranges[rank]
            corr = numpy.zeros((M, min(N, args.width)), dtype=numpy.float64)
            for j in range(node_ranges[rank], node_ranges[rank + 1]):
                X = j - node_ranges[rank]
                if not valid_rows[j]:
                    continue
                for k in range(j + 1, min(j + corr.shape[1] + 1, N)):
                    if not valid_rows[k]:
                        continue
                    Y = k - j - 1
                    corr[X, Y] = numpy.mean(norm[j, valid_rows] * norm[k, valid_rows])
            if rank == 0:
                corrs[chrom] = numpy.zeros((N, min(N, args.width)), dtype=numpy.float64)
                corrs[chrom][:node_ranges[1], :] = corr
                for j in range(1, num_procs):
                    comm.Recv(corrs[chrom][node_ranges[j]:node_ranges[j + 1], :], source=j, tag=9)
            else:
                comm.Send(corr, dest=0, tag=9)

        # write resulting matrices to hdf5 file
        if rank == 0:
            print >> sys.stderr, ("\r%s\rResolution %i - Writing results") % (' ' * 120, res),
            outfile = h5py.File(args.output, 'a')
            for chrom in args.chroms:
                if valids[chrom] is None:
                    outfile.attrs['%s.%i.invalid' % (chrom, res)] = True
                else:
                    outfile.create_dataset(name="valid.%s.%i" % (chrom, res), data=valids[chrom])
                    outfile.create_dataset(name="dist.%s.%i" % (chrom, res), data=dists[chrom])
                    outfile.create_dataset(name="corr.%s.%i" % (chrom, res), data=corrs[chrom])
            outfile.close()
    if rank == 0:
        print >> sys.stderr, ("\r%s\r") % (' ' * 120),
    return None

def transfer_dict(data, dest, source):
    if rank == dest:
        key = comm.recv(source=source, tag=5)
        while key:
            shape, dtype = comm.recv(source=source, tag=6)
            if shape is None:
                data[key] = None
            else:
                data[key] = numpy.zeros(shape, dtype=dtype)
                comm.Recv(data[key], source=source, tag=7)
            key = comm.recv(source=source, tag=5)
    elif rank == source:
        for key, value in data.iteritems():
            comm.send(key, dest=dest, tag=5)
            if value is None:
                comm.send([None, None], dest=dest, tag=6)
            else:
                comm.send([value.shape, value.dtype], dest=dest, tag=6)
                comm.Send(value, dest=dest, tag=7)
        comm.send(False, dest=dest, tag=5)
    return None

def downsample(data, indices, target_count, rng=None):
    if target_count == 0:
        return numpy.copy(data), numpy.copy(indices)
    if rng is None:
        rng = numpy.random.RandomState()
    initial_count = numpy.sum(data[:, 2])
    percent = target_count / float(initial_count)
    # select which reads to keep, based on percent of reads to keep
    keep = rng.rand(initial_count) < percent
    # adjust mismatch between selected read count and target read count by selecting reads to add/remove
    kept = numpy.sum(keep)
    if kept > target_count:
        pool_size = kept
        adjust_size = kept - target_count
        remove = True
    elif kept < target_count:
        pool_size = initial_count - kept
        adjust_size = target_count - kept
        remove = False
    else:
        adjust_size = 0
    reads = {}
    while len(reads) < adjust_size:
        temp_rand = rng.randint(0, pool_size, adjust_size * 2)
        for i in range(temp_rand.shape[0]):
            reads[temp_rand[i]] = None
            if len(reads) == adjust_size:
                break
    if adjust_size > 0:
        if remove:
            where = numpy.where(keep)[0]
            for i in where[reads.keys()]:
                keep[i] = False
        else:
            where = numpy.where(numpy.logical_not(keep))[0]
            for i in where[reads.keys()]:
                keep[i] = True
    # adjust read counts in data
    counts = numpy.repeat(numpy.arange(data.shape[0]), data[:, 2])
    new_data = numpy.copy(data)
    new_data[:, 2] = numpy.bincount(counts, weights=keep, minlength=data.shape[0])
    new_indices = numpy.zeros(indices.shape[0], dtype=numpy.int64)
    for i in range(1, new_indices.shape[0]):
        new_indices[i] = numpy.sum(new_data[indices[i - 1]:indices[i], 2] > 0) + new_indices[i - 1]
    new_data = new_data[numpy.where(new_data[:, 2] > 0)[0], :]
    return new_data, new_indices

def normalize(raw, mids, binsize, width):
    start = (mids[0] / binsize) * binsize
    stop = ((mids[-1] - 1) / binsize + 1) * binsize
    N = ((stop - start) / binsize).astype(numpy.int64)
    mapping = (mids - start) / binsize
    counts = numpy.copy(raw)
    counts[:, 0] = mapping[counts[:, 0]]
    counts[:, 1] = mapping[counts[:, 1]]
    data = numpy.bincount(counts[:, 0] * N + counts[:, 1], minlength=(N * N), weights=counts[:, 2]).reshape(N, N)
    indices = numpy.triu_indices(N, 0)
    data[indices[1], indices[0]] = data[indices]
    data[numpy.arange(N), numpy.arange(N)] *= 2
    data = data.astype(numpy.float64)
    row_counts = numpy.bincount(mapping, minlength=N)
    prev_valid_rows = N + 1
    valid_rows = numpy.sum(data > 0, axis=1) > 1
    while prev_valid_rows > numpy.sum(valid_rows):
        data[numpy.logical_not(valid_rows), :] = 0
        data[:, numpy.logical_not(valid_rows)] = 0
        prev_valid_rows = numpy.sum(valid_rows)
        valid_rows = numpy.sum(data > 0, axis=1) > 1
    if prev_valid_rows == 0:
        return None, None, None
    data /= numpy.maximum(1, row_counts).reshape(-1, 1)
    data /= numpy.maximum(1, row_counts).reshape(1, -1)
    dist = numpy.copy(data)
    for i in range(N):
        temp1 = numpy.arange(N - i)
        temp2 = numpy.arange(i, N)
        bg = numpy.sum(data[temp1, temp2])
        count = float(numpy.sum(valid_rows[temp1] & valid_rows[temp2]))
        if bg > 0:
            dist[temp1, temp2] /= bg / count
            if i > 0:
                dist[temp2, temp1] = dist[temp1, temp2]
    corrections = numpy.ones(numpy.sum(valid_rows), dtype=numpy.float64)
    temp = dist[valid_rows, :][:, valid_rows]
    where = numpy.where(temp > 0)
    temp = temp[where]
    change = 1.0
    iteration = 0
    while change > 0.01 and iteration < 100:
        weights1 = temp / corrections[where[0]]
        weights2 = temp / corrections[where[1]]
        new_corrections = numpy.bincount(where[0], weights=weights2, minlength=corrections.shape[0])
        new_corrections += numpy.bincount(where[1], weights=weights1, minlength=corrections.shape[0])
        new_corrections = numpy.maximum(0.1, numpy.minimum(10., new_corrections / corrections.shape[0]))
        #new_corrections = numpy.maximum(0.1, numpy.minimum(10., numpy.mean(temp / corrections.reshape(1, -1), axis=1)))
        change = numpy.amax(numpy.abs(corrections - new_corrections))
        corrections = new_corrections ** 0.5 * corrections ** 0.5
        iteration += 1
    data[valid_rows, :] /= corrections.reshape(-1, 1)
    data[:, valid_rows] /= corrections.reshape(1, -1)
    dist = numpy.zeros((N, min(width, N)), dtype=numpy.float64)
    for i in range(min(N - 1, 100)):
        M = N - i - 1
        temp1 = numpy.arange(M)
        temp2 = numpy.arange(i + 1, N)
        dist[:M, i] = data[temp1, temp2]
    for i in range(1, min(width, N) + 1):
        temp1 = numpy.arange(N - i)
        temp2 = numpy.arange(i, N)
        bg = numpy.sum(data[temp1, temp2])
        count = float(numpy.sum(valid_rows[temp1] * valid_rows[temp2]))
        if bg > 0:
            dist[:(N - i), i - 1] /= bg / count
    norm = numpy.zeros(data.shape, dtype=data.dtype)
    indices = numpy.triu_indices(N, 0)
    norm[indices] = numpy.log(1 + data[indices])
    norm[indices[1], indices[0]] = norm[indices]
    norm[valid_rows, :] -= numpy.mean(norm[valid_rows, :][:, valid_rows], axis=1).reshape(-1, 1)
    norm[valid_rows, :] /= numpy.std(norm[valid_rows, :][:, valid_rows], axis=1).reshape(-1, 1)
    return norm, dist, valid_rows

def generate_parser():
    """Generate an argument parser."""
    description = "%(prog)s -- Find a quality score for a HiC dataset"
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument(dest="input", type=str, action='store', help="HiFive project file name")
    parser.add_argument(dest="output", type=str, action='store', help="Quasar transformation file name")
    parser.add_argument('-r', dest="resolution", type=str, action='store', default='1000000',
        help="Comma-separated list of resolutions to find quality for")
    parser.add_argument('-c', dest="coverage", type=int, action='store', default=0, help="Number of reads to use")
    parser.add_argument('-w', dest="width", type=int, action='store', default=100, help="Number of bins to use")
    parser.add_argument('-s', dest="seed", type=int, action='store', default=1, help="Random seed")
    parser.add_argument('--chroms', dest="chroms", type=str, action='store', default='', help="A Comma-separated list of chromosomes to use. Defaults to Numbered chromosomes up to 22 (fewer if appropriate) and X.")
    return parser

if __name__ == "__main__":
    main()
