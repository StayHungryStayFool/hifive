#!/usr/bin/env python

import sys
import argparse
import subprocess

import numpy
import h5py
import hifive
from mpi4py import MPI

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
num_procs = comm.Get_size()

def main():
    if rank == 0:
        print >> sys.stderr, ("\r%s\rLoading counts") % (' ' * 120),
        parser = generate_parser()
        args = parser.parse_args()
        args.RNG = numpy.random.RandomState(seed=args.seed)
        args.resolution = args.resolution.split(',')
        for i in range(len(args.resolution)):
            args.resolution[i] = int(args.resolution[i])

        # Determine valid chromosomes
        hic = hifive.HiC(args.input)
        chromosomes = hic.fends['chromosomes'][...]
        chroms = []
        if args.chroms == '':
            for i in range(1, 23):
                if numpy.where(chromosomes == str(i))[0].shape[0] > 0:
                    chroms.append(str(i))
            for i in ['X', '2L', '2R', '3L', '3R']:
                if numpy.where(chromosomes == str(i))[0].shape[0] > 0:
                    chroms.append(str(i))
        else:
            for chrom in args.chroms.split(','):
                if numpy.where(chromosomes == chrom.strip('chr'))[0].shape[0] > 0:
                    chroms.append(chrom.strip('chr'))
        args.chroms = chroms

        # Load raw counts
        if 'binned' in hic.__dict__ and hic.binned is not None:
            temp_mids = hic.fends['bins']['mid'][...]
            chr_indices = hic.fends['bin_indices'][...]
        else:
            temp_mids = hic.fends['fends']['mid'][...]
            chr_indices = hic.fends['chr_indices'][...]
        bounds = numpy.zeros((len(args.chroms), 2), numpy.int64)
        for i, chrom in enumerate(args.chroms):
            chrint = hic.chr2int[chrom]
            bounds[i, 0] = hic.data['cis_indices'][chr_indices[chrint]]
            bounds[i, 1] = hic.data['cis_indices'][chr_indices[chrint + 1]]
        raw = numpy.zeros((numpy.sum(bounds[:, 1] - bounds[:, 0]), 3), dtype=numpy.int64)
        indices = numpy.zeros(len(args.chroms) + 1, dtype=numpy.int64)
        mids = {}
        starts = numpy.zeros(len(args.chroms), dtype=numpy.int32)
        for i, chrom in enumerate(args.chroms):
            chrint = hic.chr2int[chrom]
            indices[i + 1] = indices[i] + bounds[i, 1] - bounds[i, 0]
            temp = hic.data['cis_data'][bounds[i, 0]:bounds[i, 1], :]
            temp[:, :2] -= chr_indices[chrint]
            raw[indices[i]:indices[i + 1], :] = temp
            mids[chrom] = temp_mids[chr_indices[chrint]:chr_indices[chrint + 1]]
            starts[i] = mids[chrom][0]
        if numpy.sum(raw[:, 2]) < args.coverage:
            args = None
        else:
            outfile = h5py.File(args.output, 'w')
            outfile.create_dataset(name='chromosomes', data=numpy.array(args.chroms))
            outfile.create_dataset(name='resolutions', data=numpy.array(args.resolution))
            outfile.create_dataset(name='starts', data=starts)
            outfile.attrs['coverage'] = args.coverage
            outfile.close()
            if args.coverage > 0:
                raw, indices = downsample(raw, indices, args.coverage, args.RNG)
    else:
        args = None

    # Transfer args and reads
    args = comm.bcast(args, root=0)
    if args is None:
        if rank == 0:
            print >> sys.stderr, ("\r%s\r") % (' ' * 120),
        return None
    args.chrom_ranges = numpy.round(numpy.linspace(0, len(args.chroms), num_procs + 1)).astype(numpy.int32)
    raw_counts = {}
    if rank == 0:
        print >> sys.stderr, ("\r%s\rTransferring counts") % (' ' * 120),
        for i in range(args.chrom_ranges[1]):
            chrom = args.chroms[i]
            raw_counts[chrom] = raw[indices[i]:indices[i + 1], :]
        for i in range(1, num_procs):
            for j in range(args.chrom_ranges[i], args.chrom_ranges[i + 1]):
                chrom = args.chroms[j]
                comm.send(indices[j + 1] - indices[j], dest=i, tag=1)
                comm.Send(raw[indices[j]:indices[j + 1], :], dest=i, tag=2)
                comm.send(mids[chrom].shape[0], dest=i, tag=3)
                comm.Send(mids[chrom], dest=i, tag=4)
        del raw
    else:
        mids = {}
        for i in range(args.chrom_ranges[rank], args.chrom_ranges[rank + 1]):
            chrom = args.chroms[i]
            N = comm.recv(source=0, tag=1)
            raw_counts[chrom] = numpy.zeros((N, 3), dtype=numpy.int64)
            comm.Recv(raw_counts[chrom], source=0, tag=2)
            N = comm.recv(source=0, tag=3)
            mids[chrom] = numpy.zeros(N, dtype=numpy.int32)
            comm.Recv(mids[chrom], source=0, tag=4)

    # Cycle through desired resolutions
    for res in args.resolution:
        dists = {}
        norms = {}
        valids = {}
        corrs = {}

        # For each chromosome, normalize and find distance-corrected matrix
        if rank == 0:
            print >> sys.stderr, ("\r%s\rResolution %i - Normalizing counts") % (' ' * 120, res),
        for chrom in raw_counts:
            norm, dist, valid_rows = normalize(chrom, args, raw_counts[chrom], mids[chrom], res, args.width)
            dists[chrom] = dist
            norms[chrom] = norm
            valids[chrom] = valid_rows
        if rank == 0:
            for i in range(1, num_procs):
                transfer_dict(dists, 0, i)
                transfer_dict(norms, 0, i)
                transfer_dict(valids, 0, i)
        else:
            transfer_dict(dists, 0, rank)
            transfer_dict(norms, 0, rank)
            transfer_dict(valids, 0, rank)
            dists = None

        # cycle through chromosomes finding correlation matrices
        for i, chrom in enumerate(args.chroms):
            if rank == 0:
                print >> sys.stderr, ("\r%s\rResolution %i - Correlating chrom %s") % (' ' * 120, res, chrom),
                corrs[chrom] = find_correlations(args, norms[chrom], valids[chrom])
            else:
                find_correlations(args)

        # write resulting matrices to hdf5 file
        if rank == 0:
            print >> sys.stderr, ("\r%s\rResolution %i - Writing results") % (' ' * 120, res),
            outfile = h5py.File(args.output, 'a')
            for chrom in args.chroms:
                if valids[chrom] is None:
                    outfile.attrs['%s.%i.invalid' % (chrom, res)] = True
                else:
                    outfile.create_dataset(name="valid.%s.%i" % (chrom, res), data=valids[chrom])
                    outfile.create_dataset(name="dist.%s.%i" % (chrom, res), data=dists[chrom])
                    outfile.create_dataset(name="corr.%s.%i" % (chrom, res), data=corrs[chrom])
            outfile.close()
    if rank == 0:
        #print_hm(corrs['1'], valids['1'], compact=True, logged=False).save('%s_corrs.png' % args.output.replace('.quasar',''))
        #print_hm(corrs['1']*dists['1'], valids['1'], compact=True, logged=False).save('%s_trans.png' % args.output.replace('.quasar',''))
        print >> sys.stderr, ("\r%s\r") % (' ' * 120),
    return None

def transfer_dict(data, dest, source):
    if rank == dest:
        key = comm.recv(source=source, tag=5)
        while key:
            shape, dtype = comm.recv(source=source, tag=6)
            if shape is None:
                data[key] = None
            else:
                data[key] = numpy.zeros(shape, dtype=dtype)
                comm.Recv(data[key], source=source, tag=7)
            key = comm.recv(source=source, tag=5)
    elif rank == source:
        for key, value in data.iteritems():
            comm.send(key, dest=dest, tag=5)
            if value is None:
                comm.send([None, None], dest=dest, tag=6)
            else:
                comm.send([value.shape, value.dtype], dest=dest, tag=6)
                comm.Send(value, dest=dest, tag=7)
        comm.send(False, dest=dest, tag=5)
    return None

def downsample(data, indices, target_count, rng=None):
    if target_count == 0:
        return numpy.copy(data), numpy.copy(indices)
    if rng is None:
        rng = numpy.random.RandomState()
    initial_count = numpy.sum(data[:, 2])
    percent = target_count / float(initial_count)
    # select which reads to keep, based on percent of reads to keep
    keep = rng.rand(initial_count) < percent
    # adjust mismatch between selected read count and target read count by selecting reads to add/remove
    kept = numpy.sum(keep)
    if kept > target_count:
        pool_size = kept
        adjust_size = kept - target_count
        remove = True
    elif kept < target_count:
        pool_size = initial_count - kept
        adjust_size = target_count - kept
        remove = False
    else:
        adjust_size = 0
    reads = {}
    while len(reads) < adjust_size:
        temp_rand = rng.randint(0, pool_size, adjust_size * 2)
        for i in range(temp_rand.shape[0]):
            reads[temp_rand[i]] = None
            if len(reads) == adjust_size:
                break
    if adjust_size > 0:
        if remove:
            where = numpy.where(keep)[0]
            for i in where[reads.keys()]:
                keep[i] = False
        else:
            where = numpy.where(numpy.logical_not(keep))[0]
            for i in where[reads.keys()]:
                keep[i] = True
    # adjust read counts in data
    counts = numpy.repeat(numpy.arange(data.shape[0]), data[:, 2])
    new_data = numpy.copy(data)
    new_data[:, 2] = numpy.bincount(counts, weights=keep, minlength=data.shape[0])
    new_indices = numpy.zeros(indices.shape[0], dtype=numpy.int64)
    for i in range(1, new_indices.shape[0]):
        new_indices[i] = numpy.sum(new_data[indices[i - 1]:indices[i], 2] > 0) + new_indices[i - 1]
    new_data = new_data[numpy.where(new_data[:, 2] > 0)[0], :]
    return new_data, new_indices

def normalize(chrom, args, raw, mids, binsize, width):
    # convert into square matrix
    start = (mids[0] / binsize) * binsize
    stop = ((mids[-1] - 1) / binsize + 1) * binsize
    N = ((stop - start) / binsize).astype(numpy.int64)
    mapping = (mids - start) / binsize
    counts = numpy.copy(raw)
    counts[:, 0] = mapping[counts[:, 0]]
    counts[:, 1] = mapping[counts[:, 1]]
    data = numpy.bincount(counts[:, 0] * N + counts[:, 1], minlength=(N * N), weights=counts[:, 2]).reshape(N, N)
    indices = numpy.triu_indices(N, 0)
    data[indices[1], indices[0]] = data[indices]
    data[numpy.arange(N), numpy.arange(N)] *= 2
    data = data.astype(numpy.float64)

    # filter rows with too few observations
    row_counts = numpy.bincount(mapping, minlength=N)
    prev_valid_rows = N + 1
    # we need several non-zero observations for finding correlations
    valid_rows = numpy.sum(data > 0, axis=1) >= 5
    while prev_valid_rows > numpy.sum(valid_rows):
        data[numpy.logical_not(valid_rows), :] = 0
        data[:, numpy.logical_not(valid_rows)] = 0
        prev_valid_rows = numpy.sum(valid_rows)
        valid_rows = numpy.sum(data > 0, axis=1) > 1
    valid = numpy.where(valid_rows)[0]
    if prev_valid_rows == 0:
        return None, None, None

    # find distance dependent signal
    bg = numpy.ones(N, dtype=numpy.float64)
    for i in range(N):
        temp1 = numpy.arange(N - i)
        temp2 = numpy.arange(i, N)
        obs = numpy.sum(data[temp1, temp2])
        pos = float(numpy.sum(valid_rows[temp1] & valid_rows[temp2]))
        if obs > 0:
            bg[i] = obs / pos

    # find compact data array for weighting correlation matrix
    dist = numpy.zeros((N, min(width, N - 1)), dtype=numpy.float64)
    for i in range(dist.shape[1]):
        M = N - i - 1
        temp1 = numpy.arange(M)
        temp2 = numpy.arange(i + 1, N)
        dist[:M, i] = data[temp1, temp2]

    # find fill data array for finding correlations
    norm = numpy.zeros((N, N), dtype=numpy.float64)
    for i in valid:
        norm[i, valid] = data[i, valid]
    for i in range(N):
        temp1 = numpy.arange(N - i)
        temp2 = numpy.arange(i, N)
        norm[temp1, temp2] /= bg[i]
        norm[temp2, temp1] = norm[temp1, temp2]

    # normalize array for reducing correlation calculation time
    for i in valid:
        norm[i, valid] -= numpy.mean(norm[i, valid])
        norm[i, valid] /= numpy.std(norm[i, valid])

    return norm, dist, valid_rows

def find_correlations(args, norm=None, vrows=None):
    if rank == 0:
        if norm is not None:
            N = norm.shape[0]
        else:
            N = None
    else:
        N = None
    N = comm.bcast(N, root=0)
    if N is None:
        return None
    if rank != 0:
        norm = numpy.zeros((N, N), dtype=numpy.float64)
        vrows = numpy.zeros(N, dtype=numpy.bool)
    comm.Bcast(norm, root=0)
    comm.Bcast(vrows, root=0)
    valid = numpy.where(vrows)[0]
    node_ranges = numpy.round(numpy.linspace(0, N, num_procs + 1)).astype(numpy.int32)
    M = node_ranges[rank + 1] - node_ranges[rank]
    corr = numpy.zeros((M, min(N - 1, args.width)), dtype=numpy.float64)
    for j in range(node_ranges[rank], node_ranges[rank + 1]):
        X = j - node_ranges[rank]
        if not vrows[j]:
            continue
        for k in range(j + 1, min(j + corr.shape[1] + 1, N)):
            if not vrows[k]:
                continue
            Y = k - j - 1
            corr[X, Y] = numpy.mean(norm[j, valid] * norm[k, valid])
    if rank == 0:
        corrs = numpy.zeros((N, min(N - 1, args.width)), dtype=numpy.float64)
        corrs[:node_ranges[1], :] = corr
        for j in range(1, num_procs):
            comm.Recv(corrs[node_ranges[j]:node_ranges[j + 1], :], source=j, tag=9)
        return corrs
    else:
        comm.Send(corr, dest=0, tag=9)
    return None

def generate_parser():
    """Generate an argument parser."""
    description = "%(prog)s -- Find a quality score for a HiC dataset"
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument(dest="input", type=str, action='store', help="HiFive project file name")
    parser.add_argument(dest="output", type=str, action='store', help="Quasar transformation file name")
    parser.add_argument('-r', dest="resolution", type=str, action='store', default='1000000',
        help="Comma-separated list of resolutions to find quality for")
    parser.add_argument('-c', dest="coverage", type=int, action='store', default=0, help="Number of reads to use")
    parser.add_argument('-w', dest="width", type=int, action='store', default=100, help="Number of bins to use")
    parser.add_argument('-s', dest="seed", type=int, action='store', default=1, help="Random seed")
    parser.add_argument('--chroms', dest="chroms", type=str, action='store', default='', help="A Comma-separated list of chromosomes to use. Defaults to Numbered chromosomes up to 22 (fewer if appropriate) and X.")
    return parser

def print_hm(data, vrows, compact=False, logged=True):
    invalid = vrows == False
    temp = numpy.zeros((data.shape[0], data.shape[0], 2), dtype=numpy.float32)
    if not compact:
        temp[:, :, 0] = data
        temp[:, :, 1] = data >= 0
    else:
        N = data.shape[0]
        for i in range(data.shape[1]):
            temp[numpy.arange(N - i), numpy.arange(i, N), 0] = data[:(N - i), i]
        indices = numpy.triu_indices(N, 1)
        temp[indices[1], indices[0], 0] = temp[indices[0], indices[1], 0]
        temp[:, :, 1] = temp[:, :, 0] != 0
    temp[invalid, :, 1] = 0
    temp[:, invalid, 1] = 0
    where = numpy.where(temp[:, :, 1])
    temp1 = temp[where[0], where[1], 0]
    temp1.sort()
    temp[where[0], where[1], 0] = numpy.maximum(temp1[int(0.01 * temp1.shape[0])],
                                  numpy.minimum(temp1[int(0.99 * temp1.shape[0])],
                                  temp[where[0], where[1], 0]))
    img = hifive.plotting.plot_full_array(temp, symmetricscaling=False, logged=logged, silent=True)
    return img

if __name__ == "__main__":
    main()
